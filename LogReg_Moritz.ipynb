{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import numpy as np\n",
    "from DataUtils import DataUtil\n",
    "import time\n",
    "\n",
    "sc = pyspark.SparkContext('local[4]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.defaultParallelism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataUtil = DataUtil(sc, 'data/spam.data.txt', 'data/mean_std.txt', True)\n",
    "rdd = dataUtil.read(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParallelLogReg():\n",
    "    \n",
    "    def __init__(self, sc, dataUtils, iterations, learning_rate, lambda_reg, fit_intercept):\n",
    "        self.dataUtils = dataUtils\n",
    "        # do we need to broadcast these?\n",
    "        self.iterations = iterations\n",
    "        self.lr = learning_rate\n",
    "        self.lambda_reg = lambda_reg\n",
    "        self.fit_intercept = fit_intercept\n",
    "        self.data = self.dataUtils.read(sc)\n",
    "        self.numberObservations = self.data.count()\n",
    "        self.numberFeatures = 56\n",
    "        self.sc = sc\n",
    "        \n",
    "    def __add_intercept(self):\n",
    "        self.data = self.data.map(lambda x: (1, x[0], x[1]))\n",
    "    \n",
    "    def __sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "    \n",
    "    def __predict_y(self, w, x):\n",
    "        return self.__sigmoid(w[1].dot(x[1]) + w[0] * x[0])\n",
    "    \n",
    "    def calculateLoss(self):\n",
    "        return 1\n",
    "        \n",
    "    def train(self, SGD=False, SGD_pct=0.5):\n",
    "        self.__add_intercept()\n",
    "        \n",
    "        # initialize the weights\n",
    "        # w[0]: bias weight\n",
    "        # w[1]: rest of the weights\n",
    "        w = (0, np.zeros(self.numberFeatures))\n",
    "        loss = 0\n",
    "        \n",
    "        # initialize prediction to rdd\n",
    "        # x[0]: bias/intercept\n",
    "        # x[1]: rest features\n",
    "        # x[2]: true y\n",
    "        # adding x[3]: predicted y\n",
    "        self.data = self.data.map(lambda x: (x[0], x[1], x[2], 1 / (1 + np.exp(-(w[1].dot(x[1]) + w[0] * x[0])))))\n",
    "        \n",
    "        data = self.data.cache()\n",
    "        \n",
    "        for i in range(self.iterations):\n",
    "            start = time.time()\n",
    "            \n",
    "            # sample for SGD\n",
    "            if SGD:\n",
    "                data = self.data.sample(False, SGD_pct).cache()\n",
    "                if (i==0):\n",
    "                    self.numberObservations = data.count()\n",
    "            \n",
    "            # compute derivatives\n",
    "            temp = data.map(lambda x: ((x[3] - x[2]) * x[0], (x[3] - x[2]) * x[1])) \\\n",
    "                       .reduce(lambda a,b: (a[0] + b[0], a[1] + b[1]))\n",
    "            dw = (temp[0]/self.numberObservations, (temp[1]/self.numberObservations) + (self.lambda_reg/self.numberObservations) * w[1])\n",
    "            \n",
    "            # update weights\n",
    "            w = (w[0] - self.lr * dw[0], w[1] - self.lr * dw[1])\n",
    "            \n",
    "            # update prediction\n",
    "            data = data.map(lambda x: (x[0], x[1], x[2], 1 / (1 + np.exp(-(w[1].dot(x[1]) + w[0] * x[0]))))).cache()\n",
    "            \n",
    "            # calculate loss\n",
    "            loss = data.map(lambda x: x[2] * np.log(x[3]) + (1 - x[2]) * np.log(1 - x[3])) \\\n",
    "                                 .reduce(lambda a,b: a + b)\n",
    "            loss = -(1/self.numberObservations) * loss + (self.lambda_reg/(2*self.numberObservations)) * np.sum(w[1]**2)\n",
    "            \n",
    "            if (i%10 == 0):\n",
    "                print(\"Current loss: \" + str(loss))\n",
    "                end = time.time()\n",
    "                print(\"Iteration: \" + str(i) + \", Total Time: \" + str(end - start))\n",
    "                \n",
    "        # calculate prediction for entire data set\n",
    "        self.data = self.data.map(lambda x: (x[0], x[1], x[2], 1 / (1 + np.exp(-(w[1].dot(x[1]) + w[0] * x[0])))))\n",
    "        \n",
    "        # update loss for entire data set\n",
    "        self.numberObservations = self.data.count()\n",
    "        loss = self.data.map(lambda x: x[2] * np.log(x[3]) + (1 - x[2]) * np.log(1 - x[3])) \\\n",
    "                   .reduce(lambda a,b: a + b)\n",
    "        self.loss = -(1/self.numberObservations) * loss + (self.lambda_reg/(2*self.numberObservations)) * np.sum(w[1]**2)\n",
    "        \n",
    "        # add the predicted class        \n",
    "        self.data = self.data.map(lambda x: (x[0], x[1], x[2], x[3], 1 if x[3] >= 0.5 else 0))\n",
    "        \n",
    "        # calculate accuracy\n",
    "        self.acc = self.data.map(lambda x: 1 if x[2] == x[4] else 0) \\\n",
    "                            .reduce(lambda a,b: a+b) / self.numberObservations\n",
    "        \n",
    "        print(\"Final loss: \" + str(self.loss) + \", Accuracy: \" + str(self.acc))\n",
    "            \n",
    "        return w\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "logReg = ParallelLogReg(sc, dataUtil, 100, 0.1, 0.1, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current loss: 0.6503220242271298\n",
      "Iteration: 0, Total Time: 1.2008984088897705\n",
      "Current loss: 0.4581797205838394\n",
      "Iteration: 10, Total Time: 0.7159209251403809\n",
      "Current loss: 0.39332200478508095\n",
      "Iteration: 20, Total Time: 0.46668338775634766\n",
      "Current loss: 0.35989145975858144\n",
      "Iteration: 30, Total Time: 0.5080475807189941\n",
      "Current loss: 0.3391484146299772\n",
      "Iteration: 40, Total Time: 0.4967775344848633\n",
      "Current loss: 0.324848301239116\n",
      "Iteration: 50, Total Time: 0.5305984020233154\n",
      "Current loss: 0.3142912196692107\n",
      "Iteration: 60, Total Time: 0.5444254875183105\n",
      "Current loss: 0.30611242960061824\n",
      "Iteration: 70, Total Time: 0.6343545913696289\n",
      "Current loss: 0.2995456845167399\n",
      "Iteration: 80, Total Time: 0.5325527191162109\n",
      "Current loss: 0.29412675827114465\n",
      "Iteration: 90, Total Time: 0.5699419975280762\n",
      "Final loss: 0.2899825061314961, Accuracy: 0.9065420560747663\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-0.4283915364779883,\n",
       " array([-0.00622156, -0.06707946,  0.12603675,  0.10679152,  0.28608055,\n",
       "         0.20375194,  0.49958148,  0.24671533,  0.22264238,  0.09935942,\n",
       "         0.12813877, -0.10040145,  0.05902925,  0.04332017,  0.18387406,\n",
       "         0.36372831,  0.28676633,  0.20048329,  0.15539207,  0.22677141,\n",
       "         0.31132481,  0.19344826,  0.4381361 ,  0.26738814, -0.29162514,\n",
       "        -0.22380624, -0.25198122, -0.05837027, -0.11482588, -0.13995595,\n",
       "        -0.07090135, -0.03828431, -0.15286331, -0.03645856, -0.11456854,\n",
       "        -0.02073074, -0.1365954 , -0.05547121, -0.12921777, -0.00276266,\n",
       "        -0.11337995, -0.20190582, -0.11778833, -0.13805032, -0.23019683,\n",
       "        -0.22506779, -0.08137009, -0.11471476, -0.1139385 , -0.04269744,\n",
       "        -0.05166024,  0.33324663,  0.4674863 ,  0.11167972,  0.12264795,\n",
       "         0.28245354]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logReg.train(False, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logReg.acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
