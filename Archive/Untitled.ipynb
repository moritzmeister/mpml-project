{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn import preprocessing\n",
    "\n",
    "sc = pyspark.SparkContext('local[*]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([(1,1),(1,3), (2,2),(2,4),(2,6)])\n",
    "rdd2 = sc.parallelize(range(7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, [2, 4, 6]), (1, [1, 3])]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.combineByKey(lambda x:[x], lambda x,y: x+[y],lambda x,y:x+y).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 12), (1, 4)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.aggregateByKey(0, lambda x,y: x+y, lambda x,y: x+y).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 1), (1, 3), (2, 2), (2, 4), (2, 6)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.aggregate([], lambda x,y: x+[y], lambda x,y: x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, [0, 3, 6]), (2, [2, 5]), (1, [1, 4])]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd2.groupBy(lambda x: x % 3).mapValues(list).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#k-means parallelization\n",
    "\n",
    "initialize(c1,c2,c3)\n",
    "\n",
    "iterations = 100\n",
    "\n",
    "for i in iterations:\n",
    "    for p in dataset: #dataset contains non negligable number of data points\n",
    "        closest_centroid = compute_dist(p)\n",
    "        assign(p, clostest_centroid)\n",
    "        list_c1\n",
    "        list_c2\n",
    "        list_c3\n",
    "        \n",
    "    recompute_centroids(list...) # take the average of the coordinates\n",
    "    #move summation of the lists into the loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.textFile(\"quijote.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_rdd = flatMap(lambda x: x.slpit(' ')) \\\n",
    "    .map(lambda x: (x, 1)) \\\n",
    "    .reduceByKey(lambda x,y: x+y) \\\n",
    "    .reduce(lambda x,y; x if x[1] > y[1] else y)\n",
    "\n",
    "new_rdd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
